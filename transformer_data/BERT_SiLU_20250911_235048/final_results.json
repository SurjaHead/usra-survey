{
  "model": "BERT",
  "dataset": "MNIST",
  "activation": "SiLU",
  "final_train_accuracy": 0.9231296296296296,
  "final_val_accuracy": 0.9186666666666666,
  "final_train_loss": 0.25732594609950427,
  "final_val_loss": 0.28160964816311995,
  "epochs": 3,
  "learning_rate": 5e-05,
  "batch_size": 16,
  "num_encoders": 12,
  "num_heads": 12,
  "dimensionality": 768,
  "ffn_hidden": 3072,
  "architecture": "BERT: 12 encoders, 12 heads, FFN 768\u21923072\u2192768",
  "total_steps": 10125,
  "timestamp": "20250911_235048"
}